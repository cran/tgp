%\VignetteIndexEntry{example on exponential data}
%\VignetteKeywords{tgp}
%\VignetteDepends{tgp,akima,maptree,combinat}
%\VignettePackage{tgp}

\subsection{Synthetic 2-d Exponential Data}
\label{sec:exp}

<<echo=false,results=hide>>=
library(tgp)
library(akima)
library(maptree)
options(width=70)
@ 

The next example involves a two-dimensional input space in $[-2,6] \times
[-2,6]$.  The true response is given by 
\begin{equation} 
z(\mb{x}) =  x_1
\exp(-x_1^2 - x_2^2). \label{e:2dtoy} 
\end{equation} 
A small amount of Gaussian noise (with sd $=0.001$) is added.  Besides
its dimensionality, a key difference between this data set and the
last one is that it is not defined using step functions; this smooth
function does not have any artificial breaks between regions.  The
{\tt tgp} package provides a function for data subsampled from a grid
of inputs and outputs described by (\ref{e:2dtoy}) which concentrates
inputs ({\tt X}) more heavily in the first quadrant where the response
is more interesting.  Predictive locations ({\tt XX}) are the remaining
grid locations.
<<>>=
exp2d.data <- exp2d.rand()
X <- exp2d.data$X; Z <- exp2d.data$Z
XX <- exp2d.data$XX
@ 
CART is clearly just as inappropriate for this data as it was for
the sinusoidal data in the previous section.  However, a stationary GP
fits this data just fine.  After all, the process is quite well
behaved.  In two dimensions one has a choice between the isotropic and
separable correlation functions.  Separable is the default in the {\tt
  tgp} package.  For illustrative purposes here, I shall use the
isotropic power family.
<<echo=TRUE,results=HIDE>>=
exp.bgp <- bgp(X=X, Z=Z, XX=XX, corr="exp") 	
@
\begin{figure}[ht!]
\centering
<<label=bgp,fig=TRUE,echo=TRUE,width=12.5,height=7.5>>=
plot(exp.bgp, main='GP,')
@
\vspace{-0.5cm}
\caption{\footnotesize {\em Left:} posterior predictive mean using
  {\tt bgp} on synthetic exponential data; {\em right} image plot of
  posterior predictive variance with data locations {\tt X} (dots) and
  predictive locations {\tt XX} (circles).}
\label{f:exp:bgp}
\end{figure}
Progress indicators are suppressed. Figure \ref{f:exp:bgp} shows the
resulting posterior predictive surface under the GP in terms of means
({\em left}) and variances ({\em right}).  The sampled locations ({\tt
  X}) are shown as dots on the {\em right} image plot.  Predictive
locations ({\tt XX}) are circles.  Predictive uncertainty for the
stationary GP model is highest where sampling is lowest, despite that
the process is very uninteresting there.  If any of the surface or
perspective plots in the figure have white spaces, or holes, this is
becuase of the {\tt akima} bug mentioned in Section \ref{sec:plot}.
This is not a bug in {\tt tgp}.

A treed GP seems more appropriate for this data. It can separate out
the large uninteresting, essentially zero-response, part of the input
space from the interesting part.  The result is speedier inference,
and region-specific estimates of predictive uncertainty.  Chipman et
al.~recommend restarting the Markov chain a few times in order to
better explore the marginal posterior for $\mathcal{T}$
\cite{chip:geor:mccu:2002}.  This becomes more important for higher
dimensional inputs, requiring deeper trees.  The {\tt tgp} default is
{\tt R = 1}, i.e., one chain with no restarts.  Here two chains, 
with one restarts, are obtained using {\tt R=2}.
<<echo=TRUE,results=HIDE>>=
exp.btgp <- btgp(X=X, Z=Z, XX=XX, corr="exp", R=2)
@ 
\begin{figure}[ht!]
\centering
<<label=btgp,fig=TRUE,echo=TRUE,width=12.5,height=7.5>>=
plot(exp.btgp, main='treed GP,')
@
\vspace{-0.25cm}
<<label=btlmtrees,fig=TRUE,echo=TRUE,width=6,height=5>>=
tgp.trees(exp.btgp)
@
\vspace{-1cm}
\caption{\footnotesize {\em Left:} posterior predictive mean using
  {\tt btgp} on synthetic exponential data; {\em right} image plot of
  posterior predictive variance with data locations {\tt X} (dots) and
  predictive locations {\tt XX} (circles).}
\label{f:exp:btgp}
\end{figure}
Figure \ref{f:sin:btlm} shows the resulting posterior predictive
surface ({\em top}) and trees ({\em bottom}).  Typical runs of the
treed GP on this data find two, and if lucky three, partitions.  As
might be expected, jumping to the LLM for the uninteresting,
zero-response, part of the input space can yield even further speedups
\cite{gramacy:thesis:2005}.
<<>>=
exp.btgpllm <- btgpllm(X=X, Z=Z, XX=XX, corr="exp", R=2) 	
@
\begin{figure}[ht!]
\centering
<<label=btgpllm,fig=TRUE,echo=TRUE,width=12.5,height=7.5>>=
plot(exp.btgpllm, main='treed GP, LLM')
@
\vspace{-0.5cm}
\caption{\footnotesize {\em Left:} posterior predictive mean using
  {\tt btgpllm} on synthetic exponential data; {\em right} image plot
  of posterior predictive variance with data locations {\tt X} (dots)
  and predictive locations {\tt XX} (circles).}
\label{f:exp:btgpllm}
\end{figure}
Progress indicators show where the LLM ({\tt corr=$d$}) or the GP is
active.  Figure \ref{f:exp:btgpllm} show how similar the resulting
posterior predictive surfaces are.
